#!/bin/sh
#SBATCH --partition=gpu
#SBATCH --time=30:00:00
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=12
#SBATCH --constraint=CPU-X5650
#SBATCH --gres=gpu:2
#SBATCH --mem=48000
# Memory per node specification is in MB. It is optional. 
# The default limit is 3GB per core.
#SBATCH --job-name="M2L-T01-GPU"
#SBATCH --output=Result/M2L-T01-GPU.out
#SBATCH --mail-user=bzhang25@buffalo.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue
#Specifies that the job will be requeued after a node failure.
#The default is that the job will not be requeued.


echo "SLURM_JOBID="$SLURM_JOBID
echo "SLURM_JOB_NODELIST"=$SLURM_JOB_NODELIST
echo "SLURM_NNODES"=$SLURM_NNODES
echo "SLURMTMPDIR="$SLURMTMPDIR

cd $SLURM_SUBMIT_DIR
echo "working directory = "$SLURM_SUBMIT_DIR

module load tensorflow
module load keras
module load gcc
module list
ulimit -s unlimited
source activate tensorflow-py36


echo "Starting job..."

python CNN_Keras_Modls_2L.py

echo "All Done!"
